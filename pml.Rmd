---
title: "Practical Machine Learning Project"
author: "by CLT"
output: 
  html_document:
    keep_md: true
---  


### Preparing R environment
  
```{r, label = 'prepare_r_environment', warning=FALSE, results='hide', echo=FALSE}

## suppressing warnings and results for this code chunck
library(caret)
library(rattle)
## using RStudio so no need to call library( knitr)

``` 


## Executive Summary
The purpose of this project is to build a model to predict the manner in which a group of enthusiasts exercise.  The group uses devices such as Jawbone Up, Nike FuelBand, and Fitbit to collect data about personal activity.  In this project, only data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants will be used.  They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.  More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 


## Loading and Preprocessing Data
We first download the training and testing data files and then preprocess them.

```{r, label = 'load_and_preprocess_data'}

# downloading data files and store them into training and testing datasets
trainingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
training <- read.csv(trainingUrl, na.strings=c("NA","#DIV/0!",""))

testingUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(testingUrl, na.strings=c("NA","#DIV/0!",""))


# remove id columns
training <- training[,-c(1)]
testing <- testing[,-c(1,160)]


# remove predictor columns with mostly NA values
na_col <- which(colSums(is.na(training))>19000)
training <- training[,-na_col]
testing <- testing[,-na_col]


# remove predictor columns with near zero variance
nzv_col <- nearZeroVar(training)
training <- training[,-nzv_col]
testing <- testing[,-nzv_col]

```  


## Split Training Dataset
The downloaded training dataset is then split into 2 sets.  One set to be used to build the model and the other set for cross validation of the model.

```{r, label = 'split_training_data'}

# splitting training data into 2 sets for training and validation
set.seed(123)
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
fitTrain <- training[inTrain,]
validateTrain <- training[-inTrain,]

```  


## Create Decision Tree Model
We first build a decision tree model using the fitTrain dataset.
  
```{r, label = 'create_decision_tree_model', message=FALSE}

# building a decision tree model based on the new training dataset
ctrl <- trainControl(method="cv")
prep <- c("center", "scale")
modFit1 <- train(fitTrain$classe~., method="rpart", data=fitTrain, trControl=ctrl, preProcess=prep)
print(modFit1$finalModel)


# plotting the decision tree
fancyRpartPlot(modFit1$finalModel, main="Decision Tree Model")

```  


## Cross Validate Decision Tree Model
We then test the Decision Tree Model with the validateTrain dataset.
  
```{r, label = 'validate_decision_tree_model'}

# testing the decision tree model on the validation dataset
predict1 <- predict(modFit1, newdata=validateTrain)
confusionMatrix(predict1, validateTrain$classe)

```  
The accuracy of the model is only around 62.5%, which is far from ideal.


## Create Random Forest Model
We now build another model using Random Forest using the same fitTrain dataset.

```{r, label = 'create_random_forest_model', message=FALSE, warning=FALSE}

# building a random forest model based on the new training dataset
modFit2 <- train(fitTrain$classe ~ ., method="rf", data=fitTrain, trControl=ctrl, preProcess=prep)
print(modFit2$finalModel)


# plotting the random forest
plot(modFit2$finalModel, main="Random Forest Model")

```  
  

## Cross Validate Random Forest Model
The Random Forest Model is then checked against the validateTrain dataset.
  
```{r, label = 'validate_random_forest_model'}

# testing the random forest model on the validation dataset
predict2 <- predict(modFit2, newdata=validateTrain)
confusionMatrix(predict2, validateTrain$classe)

```  
The accuracy of the model is 99.95%, which is far more superior than the decision tree.  As such we will use this model to make predictions on the testing data.
  

## Predict Using Random Forest Model
Since the Random Forest Model has a higher accuracy rate, it will be used to predict the testing dataset.

```{r, label = 'predict_testing_dataset'}

# using the random forest model on the testing dataset
predictTest <- predict(modFit2, newdata=testing)
predictTest

```   


## Out of Sample Error
Based on the cross validation results earlier, the prediction of classe for the testing dataset is expected to have an out of sample error of 0.05% (1-.9995).


### Citations
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3ixREZXXg